import os
os.system("pip install schedule numpy pandas scikit-learn requests beautifulsoup4 scipy python-telegram-bot")
import logging
import re
import time
import threading
import schedule
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import requests
from bs4 import BeautifulSoup
from collections import Counter, defaultdict
import warnings
from scipy import stats
import math
from urllib.parse import urljoin, urlparse
from queue import Queue

from telegram import Update
from telegram.ext import Updater, CommandHandler

# Configure logging
LOG_FILE = 'bot_log.txt'
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
warnings.filterwarnings('ignore')

# Set default paths
DATA_FILE = 'game_data.csv'
MODEL_UPDATE_INTERVAL_MINUTES = 10
WEB_DATA_FILE = 'web_data.txt'

class GamePredictor:
    def __init__(self, bot_token):
         self.update_queue = Queue() # Create a queue object to be used in updater
         self.updater = Updater(bot_token, update_queue=self.update_queue) # Initialize updater with queue
         self.dispatcher = self.updater.dispatcher
         self.game_data = []
         self.historical_data = pd.DataFrame()
         self.models = {
            'lr': LinearRegression(),
            'rf': RandomForestRegressor(),
            'svr': SVR(kernel='rbf')
         }
         self.scaler = StandardScaler()
         self.load_game_data()

    def start(self):
        self.setup_handlers()
        self.schedule_data_collection()
        self.schedule_model_updates()
        self.updater.start_polling()
        self.updater.idle()

    def setup_handlers(self):
        self.dispatcher.add_handler(CommandHandler("start", self.send_welcome))
        self.dispatcher.add_handler(CommandHandler("help", self.send_help))
        self.dispatcher.add_handler(CommandHandler("url", self.handle_url))
        self.dispatcher.add_handler(CommandHandler("predict", self.handle_prediction))

    def send_welcome(self, update: Update, ):
         update.message.reply_text("Bot d·ª± ƒëo√°n game ƒë√£ s·∫µn s√†ng. S·ª≠ d·ª•ng /help ƒë·ªÉ xem h∆∞·ªõng d·∫´n.")

    def send_help(self, update: Update):
        help_text = """
C√°c l·ªánh c√≥ s·∫µn:
/predict - D·ª± ƒëo√°n k·∫øt qu·∫£ ti·∫øp theo
/stats - Xem th·ªëng k√™ chi ti·∫øt
/pattern - Ph√¢n t√≠ch m·∫´u
/trend - Xem xu h∆∞·ªõng hi·ªán t·∫°i
/analyze - Ph√¢n t√≠ch to√†n di·ªán
/history - Xem l·ªãch s·ª≠ d·ª± ƒëo√°n
/accuracy - Xem ƒë·ªô ch√≠nh x√°c
/url <web_url> <selector> - Thu th·∫≠p d·ªØ li·ªáu t·ª´ trang web
            """
        update.message.reply_text(help_text)

    def handle_url(self, update: Update):
         try:
            parts = update.message.text.split(' ', 2)
            if len(parts) < 3:
                update.message.reply_text("Vui l√≤ng cung c·∫•p URL v√† CSS selector. V√≠ d·ª•: `/url <url> <css selector>`")
                return
            url, selector = parts[1], parts[2]
            self.collect_data_from_url(url, selector, update)
            update.message.reply_text(f"ƒêang thu th·∫≠p d·ªØ li·ªáu t·ª´ {url} s·ª≠ d·ª•ng selector `{selector}`...")
         except IndexError:
            update.message.reply_text("Vui l√≤ng cung c·∫•p m·ªôt URL h·ª£p l·ªá v√† selector sau l·ªánh /url.")

    def load_game_data(self):
        """Load game data from CSV file"""
        try:
            if os.path.exists(DATA_FILE):
                self.historical_data = pd.read_csv(DATA_FILE, parse_dates=['timestamp'])
                logging.info(f"Loaded {len(self.historical_data)} records from {DATA_FILE}")
            else:
                logging.info(f"{DATA_FILE} not found, starting with empty data.")
        except Exception as e:
            logging.error(f"Error loading game data: {str(e)}")

    def save_game_data(self):
        """Save game data to CSV file"""
        try:
            self.historical_data.to_csv(DATA_FILE, index=False)
            logging.info(f"Saved {len(self.historical_data)} records to {DATA_FILE}")
        except Exception as e:
            logging.error(f"Error saving game data: {str(e)}")

    def collect_data(self):
       """Scheduled data collection (example: random number between 1 and 6)"""
       # Generate a random game result
       new_result = np.random.randint(1, 7) # simulate a dice roll
       self.record_game_result(new_result)

    def record_game_result(self, result):
        """Record a single game result to the data"""
        timestamp = datetime.now()
        new_data = pd.DataFrame({'result': [result], 'timestamp': [timestamp]})
        self.historical_data = pd.concat([self.historical_data, new_data], ignore_index=True) # Add data
        self.save_game_data() # Save to file
        logging.info(f"Recorded game result: {result} at {timestamp}")


    def collect_data_from_url(self, url, selector, update: Update):
      """Thu th·∫≠p v√† x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ URL"""
      try:
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            # Try the user-specified selector first
            elements = soup.select(selector)
            if elements:
                logging.info(f"Found data with user-provided selector '{selector}' on {url}")
            else:
                # Try common selectors as fallback. You can add to this list to increase robustness.
                common_selectors = ['p', 'span', 'div', 'li', '.result', '#result']
                for sel in common_selectors:
                    elements = soup.select(sel)
                    if elements:
                        selector = sel
                        logging.warning(f"Could not find data with '{selector}', using fallback selector '{sel}' on {url}")
                        break
                else: # If no common selectors work
                    logging.error(f"Could not find data using any selector on {url}")
                    update.message.reply_text(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu tr√™n {url} v·ªõi selector ƒë√£ cho, ho·∫∑c selector m·∫∑c ƒë·ªãnh.")
                    return

            text_data = ' '.join([el.get_text() for el in elements])
            numbers = self.extract_numbers_from_text(text_data)
             # Record valid numbers in history data
            if numbers:
              for number in numbers:
                self.record_game_result(number)
                logging.info(f"Extracted number from web: {number}")
            else:
                logging.warning(f"No numbers found on {url}")
                update.message.reply_text(f"Kh√¥ng c√≥ s·ªë n√†o ƒë∆∞·ª£c t√¨m th·∫•y tr√™n {url}")
      except requests.exceptions.RequestException as e:
            logging.error(f"Error fetching URL {url}: {str(e)}")
            update.message.reply_text(f"L·ªói khi truy c·∫≠p URL: {str(e)}")
      except Exception as e:
            logging.error(f"Error collecting data from {url}: {str(e)}")
            update.message.reply_text(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")
    
    def extract_numbers_from_text(self, text):
        """Extract numbers from text using regular expression"""
        try:
            numbers = re.findall(r'\d+', text)  # Find all sequences of digits
            return [int(num) for num in numbers]
        except Exception as e:
           logging.error(f"Error extracting numbers: {str(e)}")
           return []
        
    def schedule_data_collection(self):
        """L√™n l·ªãch thu th·∫≠p d·ªØ li·ªáu m·ªói 1 ph√∫t"""
        def run_schedule():
            while True:
                schedule.run_pending()
                time.sleep(1)

        schedule.every(1).minutes.do(self.collect_data)
        threading.Thread(target=run_schedule).start()
    
    def schedule_model_updates(self):
       """L√™n l·ªãch c·∫≠p nh·∫≠t models"""
       def run_model_updates():
           while True:
               schedule.run_pending()
               time.sleep(1)

       schedule.every(MODEL_UPDATE_INTERVAL_MINUTES).minutes.do(self.update_models)
       threading.Thread(target=run_model_updates).start()

    def update_models(self):
        """C·∫≠p nh·∫≠t c√°c model ML"""
        try:
            if len(self.historical_data) < 10:
                logging.info("Not enough data to train models.")
                return

            X = self.prepare_features()
            y = self.historical_data['result'].values
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # C·∫≠p nh·∫≠t c√°c model
            self.models['lr'].fit(X_train, y_train)
            self.models['rf'].fit(X_train, y_train)
            self.models['svr'].fit(X_train, y_train)
            
            logging.info("Models updated successfully")
            
        except Exception as e:
            logging.error(f"Model update error: {str(e)}")

    def prepare_features(self):
        """Chu·∫©n b·ªã features cho ML"""
        df = self.historical_data.copy()
        
        # T·∫°o features
        df['hour'] = df['timestamp'].dt.hour
        df['day_of_week'] = df['timestamp'].dt.dayofweek
        df['rolling_mean'] = df['result'].rolling(window=5).mean()
        df['rolling_std'] = df['result'].rolling(window=5).std()
        
        # One-hot encoding cho categorical features
        features = pd.get_dummies(df[['hour', 'day_of_week']])
        features = features.join(df[['rolling_mean', 'rolling_std']])
        
        # Fill any remaining NaN with 0
        features.fillna(0, inplace=True)
        
        return self.scaler.fit_transform(features)

    def mathematical_prediction(self, numbers):
        """1. T√≠nh to√°n to√°n h·ªçc n√¢ng cao"""
        results = {
            'basic_stats': {
                'mean': np.mean(numbers),
                'median': np.median(numbers),
                'std': np.std(numbers),
                'variance': np.var(numbers)
            },
            'distribution': {
                'skewness': stats.skew(numbers),
                'kurtosis': stats.kurtosis(numbers)
            },
            'probability': self.calculate_probability(numbers),
            'confidence_interval': stats.t.interval(alpha=0.95, df=len(numbers)-1,
                                                 loc=np.mean(numbers),
                                                 scale=stats.sem(numbers))
        }
        return results

    def calculate_probability(self, numbers):
        """T√≠nh x√°c su·∫•t chi ti·∫øt"""
        total = len(numbers)
        counter = Counter(numbers)
        basic_prob = {num: count/total for num, count in counter.items()}
        
        # T√≠nh x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán
        conditional_prob = defaultdict(dict)
        for i in range(len(numbers)-1):
            current = numbers[i]
            next_num = numbers[i+1]
            if current not in conditional_prob:
                conditional_prob[current] = defaultdict(int)
            conditional_prob[current][next_num] += 1

        # Chu·∫©n h√≥a x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán
        for current in conditional_prob:
            total = sum(conditional_prob[current].values())
            for next_num in conditional_prob[current]:
                conditional_prob[current][next_num] /= total

        return {
            'basic_probability': basic_prob,
            'conditional_probability': dict(conditional_prob)
        }

    def statistical_analysis(self, numbers):
        """2. Ph√¢n t√≠ch th·ªëng k√™ n√¢ng cao"""
        analysis = {
            'descriptive_stats': pd.Series(numbers).describe().to_dict(),
            'quartiles': {
                'Q1': np.percentile(numbers, 25),
                'Q2': np.percentile(numbers, 50),
                'Q3': np.percentile(numbers, 75),
                'IQR': np.percentile(numbers, 75) - np.percentile(numbers, 25)
            },
            'distribution_tests': {
                'normality': stats.normaltest(numbers),
                'uniformity': stats.kstest(numbers, 'uniform')
            },
            'trend_analysis': self.analyze_trend(numbers)
        }
        return analysis

    def analyze_trend(self, numbers):
        """Ph√¢n t√≠ch xu h∆∞·ªõng"""
        diff = np.diff(numbers)
        return {
            'trend_direction': 'increasing' if np.mean(diff) > 0 else 'decreasing',
            'trend_strength': abs(np.mean(diff)),
            'volatility': np.std(diff),
            'momentum': sum(1 for x in diff if x > 0) / len(diff)
        }

    def machine_learning_prediction(self, numbers):
        """3. D·ª± ƒëo√°n m√°y h·ªçc n√¢ng cao"""
        if len(numbers) < 10:
            return None

        # Chu·∫©n b·ªã data
        X = np.array([numbers[i:i+5] for i in range(len(numbers)-5)])
        y = np.array(numbers[5:])
        
        # Train multiple models
        predictions = {}
        for name, model in self.models.items():
            model.fit(X, y)
            pred = model.predict([numbers[-5:]])[0]
            predictions[name] = pred
        
        # Ensemble prediction
        ensemble_pred = np.mean(list(predictions.values()))
        
        return {
            'individual_predictions': predictions,
            'ensemble_prediction': ensemble_pred,
            'confidence': self.calculate_prediction_confidence(predictions)
        }

    def calculate_prediction_confidence(self, predictions):
        """T√≠nh ƒë·ªô tin c·∫≠y c·ªßa d·ª± ƒëo√°n"""
        values = list(predictions.values())
        return {
            'std_dev': np.std(values),
            'range': max(values) - min(values),
            'confidence_score': 1 / (1 + np.std(values))
        }

    def pattern_analysis(self, numbers):
        """6. Ph√¢n t√≠ch m·∫´u n√¢ng cao"""
        patterns = {
            'sequences': self.find_sequences(numbers),
            'repeating_patterns': self.find_repeating_patterns(numbers),
            'cycle_analysis': self.analyze_cycles(numbers)
        }
        return patterns

    def find_sequences(self, numbers):
        """T√¨m c√°c chu·ªói s·ªë"""
        sequences = []
        current_seq = [numbers[0]]
        
        for i in range(1, len(numbers)):
            if numbers[i] == numbers[i-1] + 1:
                current_seq.append(numbers[i])
            else:
                if len(current_seq) > 1:
                    sequences.append(current_seq)
                current_seq = [numbers[i]]
        
        return sequences

    def find_repeating_patterns(self, numbers):
        """T√¨m m·∫´u l·∫∑p l·∫°i"""
        patterns = {}
        for length in range(2, 6):
            for i in range(len(numbers) - length):
                pattern = tuple(numbers[i:i+length])
                if pattern in patterns:
                    patterns[pattern] += 1
                else:
                    patterns[pattern] = 1
        
        return dict(sorted(patterns.items(), key=lambda x: x[1], reverse=True)[:5])

    def analyze_cycles(self, numbers):
        """Ph√¢n t√≠ch chu k·ª≥"""
        fft = np.fft.fft(numbers)
        frequencies = np.fft.fftfreq(len(numbers))
        dominant_cycles = sorted([(abs(fft[i]), 1/abs(freq)) 
                                for i, freq in enumerate(frequencies) 
                                if freq > 0], reverse=True)[:3]
        return dominant_cycles

    def evolutionary_algorithm(self, numbers):
        """9. Thu·∫≠t to√°n ti·∫øn h√≥a n√¢ng cao"""
        class Individual:
            def __init__(self, genes):
                self.genes = genes
                self.fitness = 0

            def calculate_fitness(self, target):
                self.fitness = -abs(sum(self.genes) - target)
                return self.fitness

        class Population:
            def __init__(self, size, gene_length):
                self.individuals = [Individual(np.random.randint(0, 10, gene_length)) 
                                  for _ in range(size)]

            def evolve(self, generations, target):
                for gen in range(generations):
                    # T√≠nh fitness
                    for ind in self.individuals:
                        ind.calculate_fitness(target)
                    
                    # S·∫Øp x·∫øp theo fitness
                    self.individuals.sort(key=lambda x: x.fitness, reverse=True)
                    
                    # Ch·ªçn l·ªçc
                    next_gen = self.individuals[:len(self.individuals)//2]
                    
                    # Lai gh√©p
                    while len(next_gen) < len(self.individuals):
                        parent1, parent2 = np.random.choice(next_gen, 2)
                        crossover_point = np.random.randint(0, len(parent1.genes))
                        child_genes = np.concatenate([parent1.genes[:crossover_point],
                                                    parent2.genes[crossover_point:]])
                        next_gen.append(Individual(child_genes))
                    
                    # ƒê·ªôt bi·∫øn
                    for ind in next_gen[1:]:
                        if np.random.random() < 0.1:
                            mutation_point = np.random.randint(0, len(ind.genes))
                            ind.genes[mutation_point] = np.random.randint(0, 10)
                    
                    self.individuals = next_gen

                return self.individuals[0]

        # S·ª≠ d·ª•ng thu·∫≠t to√°n ti·∫øn h√≥a
        target_sum = sum(numbers[-5:])
        pop = Population(size=50, gene_length=5)
        best_individual = pop.evolve(generations=100, target=target_sum)
        
        return {
            'predicted_sequence': best_individual.genes.tolist(),
            'fitness': best_individual.fitness,
            'target_sum': target_sum
        }

    def opportunity_analysis(self, numbers):
        """10. Ph√¢n t√≠ch c∆° h·ªôi n√¢ng cao"""
        analysis = {
            'current_trend': self.analyze_current_trend(numbers),
            'momentum_indicators': self.calculate_momentum(numbers),
            'volatility_analysis': self.analyze_volatility(numbers),
            'opportunity_score': self.calculate_opportunity_score(numbers)
        }
        return analysis

    def analyze_current_trend(self, numbers):
        """Ph√¢n t√≠ch xu h∆∞·ªõng hi·ªán t·∫°i"""
        if len(numbers) < 2:
            return None
            
        recent_numbers = numbers[-10:]
        trend = {
            'direction': 'up' if recent_numbers[-1] > recent_numbers[0] else 'down',
            'strength': abs(recent_numbers[-1] - recent_numbers[0]),
            'consistency': sum(1 for i in range(1, len(recent_numbers))
                             if (recent_numbers[i] - recent_numbers[i-1] > 0) == 
                                (recent_numbers[-1] > recent_numbers[0])) / (len(recent_numbers)-1)
        }
        return trend

    def calculate_momentum(self, numbers):
        """T√≠nh momentum"""
        return {
            'roc': (numbers[-1] - numbers[0]) / numbers[0] if numbers[0] != 0 else 0,
            'acceleration': np.diff(np.diff(numbers)).mean(),
            'moving_average': pd.Series(numbers).rolling(window=5).mean().iloc[-1]
        }

    def analyze_volatility(self, numbers):
        """Ph√¢n t√≠ch bi·∫øn ƒë·ªông"""
        returns = np.diff(numbers) / numbers[:-1]
        return {
            'historical_volatility': np.std(returns) * np.sqrt(252),
            'average_true_range': sum(abs(high - low) 
                                    for high, low in zip(numbers[1:], numbers[:-1])) / (len(numbers)-1)
        }

    def calculate_opportunity_score(self, numbers):
        """T√≠nh ƒëi·ªÉm c∆° h·ªôi"""
        trend = self.analyze_current_trend(numbers)
        momentum = self.calculate_momentum(numbers)
        volatility = self.analyze_volatility(numbers)
        
        score = 0
        if trend['direction'] == 'up':
            score += trend['strength'] * trend['consistency']
        score += momentum['roc'] * 100
        score -= volatility['historical_volatility']
        
        return max(min(score, 100), 0)  # Normalize to 0-100
    
    def handle_prediction(self, update: Update):
        """X·ª≠ l√Ω l·ªánh d·ª± ƒëo√°n"""
        try:
            if len(self.historical_data) < 10:
                update.message.reply_text("C·∫ßn √≠t nh·∫•t 10 s·ªë ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c.")
                return

            numbers = self.historical_data['result'].tolist()
            # T·ªïng h·ª£p c√°c ph∆∞∆°ng ph√°p d·ª± ƒëo√°n
            math_pred = self.mathematical_prediction(numbers)
            stat_analysis = self.statistical_analysis(numbers)
            ml_pred = self.machine_learning_prediction(numbers)
            patterns = self.pattern_analysis(numbers)
            evolution_result = self.evolutionary_algorithm(numbers)
            opportunities = self.opportunity_analysis(numbers)

            # Create report
            report = f"""
üìä B√°o c√°o d·ª± ƒëo√°n:

1. Ph√¢n t√≠ch to√°n h·ªçc:
- Trung b√¨nh: {math_pred['basic_stats']['mean']:.2f}
- ƒê·ªô l·ªách chu·∫©n: {math_pred['basic_stats']['std']:.2f}
- Kho·∫£ng tin c·∫≠y: [{math_pred['confidence_interval'][0]:.2f}, {math_pred['confidence_interval'][1]:.2f}]

2. Ph√¢n t√≠ch th·ªëng k√™:
- Xu h∆∞·ªõng: {stat_analysis['trend_analysis']['trend_direction']}
- ƒê·ªô m·∫°nh xu h∆∞·ªõng: {stat_analysis['trend_analysis']['trend_strength']:.2f}

3. D·ª± ƒëo√°n m√°y h·ªçc:
- Ensemble: {ml_pred['ensemble_prediction']:.2f}
- ƒê·ªô tin c·∫≠y: {ml_pred['confidence']['confidence_score']:.2f}

4. M·∫´u ph·ªï bi·∫øn:
{patterns['repeating_patterns']}

5. C∆° h·ªôi:
- ƒêi·ªÉm c∆° h·ªôi: {opportunities['opportunity_score']:.2f}/100
- Xu h∆∞·ªõng: {opportunities['current_trend']['direction']}
- ƒê·ªô m·∫°nh: {opportunities['current_trend']['strength']:.2f}

üéØ D·ª± ƒëo√°n cu·ªëi c√πng: {ml_pred['ensemble_prediction']:.2f}
‚ö†Ô∏è ƒê·ªô tin c·∫≠y: {ml_pred['confidence']['confidence_score']*100:.2f}%
            """

            update.message.reply_text(report)
            
        except Exception as e:
            logging.error(f"Prediction error: {str(e)}")
            update.message.reply_text("C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh d·ª± ƒëo√°n.")

if __name__ == "__main__":
    bot_token = "7755708665:AAEOgUu_rYrPnGFE7_BJWmr8hw9_xrZ-5e0"
    predictor = GamePredictor(bot_token)
    predictor.start()